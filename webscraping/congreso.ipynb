{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ain-qoflDswb"
      },
      "source": [
        "# Con la página dinámica\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import os\r\n",
        "import glob\r\n",
        "import pytest\r\n",
        "import time\r\n",
        "import json\r\n",
        "from selenium import webdriver\r\n",
        "from selenium.webdriver.common.by import By\r\n",
        "from selenium.webdriver.common.action_chains import ActionChains\r\n",
        "from selenium.webdriver.support import expected_conditions\r\n",
        "from selenium.webdriver.support.wait import WebDriverWait\r\n",
        "from selenium.webdriver.common.keys import Keys\r\n",
        "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\r\n",
        "\r\n",
        "os.chdir(r\"C:\\Users\\Andrés\\OneDrive\\Desktop\\jupyter notebook\")\r\n",
        "options = webdriver.ChromeOptions()\r\n",
        "\r\n",
        "# Inicia con la ventana maximizada\r\n",
        "options.add_argument(\"--start-maximized\")\r\n",
        "driver = webdriver.Chrome(r\"C:\\Users\\IDEAPAD530S\\anaconda3\\Lib\\site-packages\\chromedriver_binary\\chromedriver.exe\", chrome_options=options)\r\n",
        "\r\n",
        "pags = 11\r\n",
        "\r\n",
        "for clicker in np.arange(0,pags,1):\r\n",
        "    # Abre el URL\r\n",
        "    driver.get(\"http://www.congreso.gob.pe/pley-2016-2021\")\r\n",
        "\r\n",
        "    # Trabajemos con iFrames\r\n",
        "    driver.switch_to.frame(0)\r\n",
        "    clicker_h = clicker\r\n",
        "    \r\n",
        "    if clicker!=0:\r\n",
        "        # Da click para el siguiente tramo de PL\r\n",
        "        while clicker_h > 0:\r\n",
        "            driver.find_element(By.XPATH, \"//img[contains(@src, '/Sicr/TraDocEstProc/CLProLey2016.nsf/8eac1ef603908b5105256cdf006c41b1/$Body/0.D90?OpenElement&FieldElemFormat=gif')]\").click()\r\n",
        "            time.sleep(2)\r\n",
        "            clicker_h = clicker_h - 1 \r\n",
        "    else:\r\n",
        "        pass\r\n",
        "    element = driver.find_element_by_xpath('//*')\r\n",
        "    element = element.get_attribute('innerHTML')\r\n",
        "    sub_url = 'http://www2.congreso.gob.pe/'\r\n",
        "\r\n",
        "    # VARIABLES DE LA RUTA ORIGINAL\r\n",
        "    a = driver.find_elements(By.XPATH,'//a[contains(@href, \"/Sicr/TraDocEstProc/CLProLey2016.nsf/641842f7e5d631bd052578e20058a231\")]')\r\n",
        "    d = driver.find_elements(By.XPATH,'//td/font[contains(@size, \"1\") and (contains(@face, \"Verdana\"))]')\r\n",
        "    b = driver.find_elements(By.XPATH,'//td[contains(@align, \"center\")][3]/font[contains(@size, \"2\") and (contains(@face, \"Verdana\"))]')\r\n",
        "    c = driver.find_elements(By.XPATH,'//td[contains(@align, \"center\")][4]/font[contains(@size, \"2\") and (contains(@face, \"Verdana\"))]')\r\n",
        "    links = driver.find_elements(By.XPATH,'//td[contains(@align, \"center\")][1]/font[contains(@size, \"2\") and (contains(@face, \"Verdana\"))]/a')\r\n",
        "    \r\n",
        "    # VARIABLES RECURSIVAS (POR CADA URL) EXCEPTUANDO LA PRIMERA\r\n",
        "    links_t = []\r\n",
        "    pdfs = []\r\n",
        "    partidos = []\r\n",
        "    sumillas = []\r\n",
        "    autores = []\r\n",
        "\r\n",
        "    for i in np.arange(0,len(links),1):\r\n",
        "        #print(links[i].get_attribute(\"href\"))\r\n",
        "        links_t2 = links[i].get_attribute(\"href\")\r\n",
        "        links_t.append(links_t2)\r\n",
        "\r\n",
        "    # VARIABLES ORIGINALES\r\n",
        "    x = []\r\n",
        "    y = []\r\n",
        "    z = []\r\n",
        "    w = []\r\n",
        "\r\n",
        "    for i in np.arange(0,len(a),1):\r\n",
        "        print(a[i].text, b[i].text, c[i].text, d[i].text)\r\n",
        "        x.append(a[i].text)\r\n",
        "        y.append(b[i].text)\r\n",
        "        z.append(c[i].text)\r\n",
        "        w.append(d[i].text)\r\n",
        "\r\n",
        "    # ENTRANDO A CADA URL Y EXTRAYENDO PDF, PARTIDO Y SUMILLA    \r\n",
        "    for i in np.arange(0,len(links_t),1):\r\n",
        "        url = links_t[i]\r\n",
        "        driver.get(url)\r\n",
        "        window_before = driver.window_handles[0]\r\n",
        "        partido = driver.find_element(By.XPATH, '//tr[contains(@valign,\"top\")][6]/td[contains(@width,\"472\")]/font')\r\n",
        "        partidos.append(partido.text)\r\n",
        "        sumilla = driver.find_element(By.XPATH, '//tr[contains(@valign,\"top\")][8]/td[contains(@width,\"472\")]/font')\r\n",
        "        sumillas.append(sumilla.text)\r\n",
        "        autor = driver.find_element(By.XPATH, '//tr[contains(@valign,\"top\")][9]/td[contains(@width,\"472\")]/font')\r\n",
        "        autores.append(autor.text)\r\n",
        "        driver.find_element(By.LINK_TEXT, \"Ver Expediente Digital\").click()\r\n",
        "        window_after = driver.window_handles[1]\r\n",
        "        driver.switch_to_window(window_after)\r\n",
        "        pdf = driver.find_element(By.XPATH, '//td[contains(@width,\"61%\") and (contains(@bgcolor, \"#FFFFFF\"))]//a')\r\n",
        "        pdfs.append(pdf.get_attribute(\"href\"))\r\n",
        "        driver.close()\r\n",
        "        driver.switch_to_window(window_before)\r\n",
        "\r\n",
        "    data = list(zip(x,y,z,w,links_t,partidos,sumillas,pdfs,autores))\r\n",
        "    columns = ['Número','Fecha Presentación','Estado','Título del Proyecto','URL','Partido','Sumilla','PDF','Autores']\r\n",
        "    data = pd.DataFrame(data, columns=columns)\r\n",
        "    excel = 'congreso' + str(clicker) + '.xlsx'\r\n",
        "    data.to_excel(excel,index=False)\r\n",
        "    \r\n",
        "df = 'congreso' + str(0) + '.xlsx'\r\n",
        "df = pd.read_excel(df)\r\n",
        "\r\n",
        "for i in np.arange(1,pags,1):\r\n",
        "    data = 'congreso' + str(i) + '.xlsx'\r\n",
        "    datas = pd.read_excel(data)\r\n",
        "    df = df.append(datas, ignore_index = True)\r\n",
        "\r\n",
        "# BASE DE DATOS FINAL\r\n",
        "df = df.drop_duplicates()\r\n",
        "df.to_excel('compilado_congreso.xlsx', index=False)\r\n",
        "\r\n",
        "# REMOVIENDO ARCHIVOS INNECESARIOS\r\n",
        "for f in glob.glob(\"congreso*.xlsx\"):\r\n",
        "    os.remove(f)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}